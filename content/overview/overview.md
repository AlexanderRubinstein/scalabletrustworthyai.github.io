+++
+++

Artificial intelligence (AI) bears hope for a positive u-turn for humanity. AI could help us fight climate change by optimising power usage. AI has the potential to increase overall human productivity to balance out the ageing population and economic slowdown.

At the same time, **many find it hard to trust AI systems**. This is often because it is hard to understand the mechanism. But more worryingly because it actually fails to work when the distribution shifts from the training data; even more seriously because it sometimes causes harm to humanity, for example, by exacerbating political polarisation and by jeopardising fairness and free will.

This leads to our study of **Trustworthy AI**. We focus on three aspects among other important topics for trustworthiness:

1. **Robustness**: we need to maximise the generalisation capabilities of AI beyond the training environment.
2. **Uncertainty**: AI needs to know and communicate to humans when it does not know the answer.
3. **Explainability**: the mechanism behind AI's recognition and decisions needs to be understandable to humans.

We will better understand the status quo of AI in terms of its trustworthiness. We will develop new technologies to enhance trustworthiness. We hope that such efforts will lessen the negative impact of AI on humanity and promote its positive applications.

There are many researchers and research labs around the world who share this view and make important contributions on Trustworthy AI. We define our uniqueness by striving for a *working* solution that is *widely applicable* and can be *deployed at large-scale*. We name our group **Scalable Trustworthy AI**. Striving for scalability requires our commitment to some key principles:

1. **Simple is better than complex**. Scalability is inversely correlated with complexity.
2. **"Why it works" must be understood**. When you understand, you can control and scale.
3. **Do not follow a dead end**. When an approach is fundamentally limited in the long run, don't go there.

We hope our research makes AI systems more trustable. We hope our technologies do work and scale well in practice. We hope our research will lead to AI-led advances for humanity while minimising the side-effects.
